{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "change_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpL1-aOe1j8z"
      },
      "source": [
        "## Note \n",
        "This notebook loads the dataset (images already cropped and best patches kept) and trains the model to detect buildings changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvY8b3U9o9kY"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfkupHTI59Tq"
      },
      "source": [
        "!ls -al drive/My\\ Drive/data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcmx86EBoecK"
      },
      "source": [
        "train_imgs = np.load(\"drive/My Drive/data2/imgs_final_dataset.npy\")\n",
        "train_labels = np.load(\"drive/My Drive/data2/labels_final_dataset.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGUNXL4rseN3"
      },
      "source": [
        "train_imgs.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GASmfoC-ZpcJ"
      },
      "source": [
        "plt.imshow(train_labels[300,:,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K7G4SsaZs6X"
      },
      "source": [
        "plt.imshow(train_labels[900,:,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_2xmkwpbSm6"
      },
      "source": [
        "a=train_labels[300,:,:,0]\n",
        "a[a>0]=1\n",
        "b=train_labels[900,:,:,0]\n",
        "c=a-b\n",
        "c[c==-1]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgpQweqyZ100"
      },
      "source": [
        "plt.imshow(c, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3At93ztc0DJ"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1onUP7c0DL"
      },
      "source": [
        "img_size = 200\n",
        "img_input = tf.keras.layers.Input(shape=(img_size, img_size, 6)) # classical unet\n",
        "\n",
        "#encoder\n",
        "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
        "conv1 = layers.Dropout(0.2)(conv1)\n",
        "conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = layers.MaxPooling2D((2, 2))(conv1) # classical unet\n",
        "\n",
        "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = layers.Dropout(0.2)(conv2)\n",
        "conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = layers.MaxPooling2D((2, 2))(conv2) # classical unet\n",
        "\n",
        "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = layers.Dropout(0.2)(conv3)\n",
        "conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "#pool3 = layers.MaxPooling2D((2, 2))(conv3) # classical unet\n",
        "\n",
        "#bottleneck\n",
        "#convl = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "#convl = layers.Dropout(0.2)(convl)\n",
        "#convl = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(convl)\n",
        "\n",
        "#decoder\n",
        "#up0 = layers.concatenate([layers.UpSampling2D((2, 2))(convl), conv3], axis=-1)  # classical unet\n",
        "#conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up0)\n",
        "#conv4 = layers.Dropout(0.2)(conv4)\n",
        "#conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "#up1 = layers.concatenate([layers.UpSampling2D((2, 2))(conv4), conv2], axis=-1)  # classical unet\n",
        "up1 = layers.concatenate([layers.UpSampling2D((2, 2))(conv3), conv2], axis=-1)  # classical unet\n",
        "conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv5 = layers.Dropout(0.2)(conv5)\n",
        "conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "up2 = layers.concatenate([layers.UpSampling2D((2, 2))(conv5), conv1], axis=-1)  # classical unet\n",
        "conv6 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv6 = layers.Dropout(0.2)(conv6)\n",
        "conv6 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "out = layers.Conv2D( 1, (1, 1) , activation='relu', padding='same')(conv6)\n",
        "out = layers.Reshape((img_size, img_size, 1))(out) # classical unet\n",
        "\n",
        "model = models.Model(inputs=img_input, outputs=out)\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URN-MvUac0DY"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDDMy3gKc0Do"
      },
      "source": [
        "model.fit(x = train_imgs[:1400], y = train_labels[:1400], validation_data=(train_imgs[1400:1600], train_labels[1400:1600]), epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ9ZPcNuLtbl"
      },
      "source": [
        "model.save(\"drive/My Drive/data2/model_weights\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFaqq5SuMBTP"
      },
      "source": [
        "model = tf.keras.models.load_model(\"drive/My Drive/data2/model_weights\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kwhGz8SsARz"
      },
      "source": [
        "res = model.predict(train_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFEirU9I5-Pj"
      },
      "source": [
        "number = 4\n",
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "indices = [1500,1650,1750,1820]\n",
        "for index in range(number):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, number, index + 1)\n",
        "    plt.imshow(train_labels[indices[index],:,:,0], cmap=\"gray\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, number, index + 1 + number)\n",
        "    plt.imshow(res[indices[index],:,:,0], cmap=\"gray\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKLTUX5-PaBf"
      },
      "source": [
        "plt.imshow(train_imgs[400,:,:,3:], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxpoAsKzsrQj"
      },
      "source": [
        "plt.imshow(train_labels[1700,:,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OinTFu7sLEq"
      },
      "source": [
        "plt.imshow(res[1700, :,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}